# ğŸ“„ Contract RAG Assistant

A local, privacy-focused Retrieval Augmented Generation (RAG) system for analyzing contract documents using Ollama, ChromaDB, and Streamlit.

## ğŸŒŸ Features

- **100% Local & Private**: All processing happens on your machine, no data sent to external APIs
- **Multi-Document Support**: Upload and query multiple PDF contracts
- **Intelligent Search**: Uses semantic search to find relevant information
- **Chat Interface**: User-friendly web interface powered by Streamlit
- **Source Attribution**: Shows which documents were used to answer questions
- **Multilingual Support**: Supports Turkish and other languages

## ğŸ—ï¸ Architecture

```
Contract PDFs â†’ Document Processor â†’ Text Chunks â†’ HuggingFace Embeddings
                                                           â†“
User Question â†’ Vector Search (ChromaDB) â†’ Relevant Chunks â†’ Ollama llama3.2 â†’ Answer
```

**Components:**
- **Document Processor**: Loads and chunks PDF files
- **Vector Store**: ChromaDB for storing and searching embeddings
- **RAG Pipeline**: Combines retrieval with Ollama LLM for answers
- **Streamlit UI**: Web interface for interaction

## ğŸ“ Project Structure

```
contract_rag/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ contracts/          # Store your PDF contracts here
â”‚   â””â”€â”€ chroma_db/          # Vector database (auto-created)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ document_processor.py   # PDF loading and chunking
â”‚   â”œâ”€â”€ vector_store.py         # ChromaDB integration
â”‚   â””â”€â”€ rag_pipeline.py         # RAG logic with Ollama
â”œâ”€â”€ app.py                      # Streamlit web interface
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Installation

### Prerequisites

1. **Python 3.8+**
2. **Ollama** installed and running
   ```bash
   # Install Ollama from: https://ollama.ai

   # Pull llama3.2 model
   ollama pull llama3.2
   ```

### Setup

1. **Clone or download this project**

2. **Install dependencies**
   ```bash
   cd contract_rag
   pip install -r requirements.txt
   ```

3. **Verify Ollama is running**
   ```bash
   ollama list
   # Should show llama3.2
   ```

## ğŸ’» Usage

### Start the Application

```bash
streamlit run app.py
```

The web interface will open at `http://localhost:8501`

### Using the Interface

1. **Upload PDFs**
   - Click "Browse files" in the sidebar
   - Select your contract PDF(s)
   - Click "Process Uploaded PDFs"
   - Wait for processing (first time takes 2-5 minutes)

2. **Ask Questions**
   - Type your question in the chat input
   - Example: "What is the contract duration?"
   - View the answer and source documents

3. **Adjust Settings**
   - Use the sidebar slider to change number of source chunks (k)
   - Clear chat history to start fresh

### Example Questions

- "What is the cancellation policy?"
- "What are the payment terms?"
- "Is there an early termination fee?"
- "What are my obligations under this contract?"

## ğŸ”§ Configuration

### Change LLM Model

Edit `app.py` and `src/rag_pipeline.py`:
```python
model_name="llama3.2"  # Change to any Ollama model
```

### Adjust Chunk Size

Edit `src/document_processor.py`:
```python
chunk_size=1000,      # Larger = more context per chunk
chunk_overlap=200     # Overlap between chunks
```

### Change Embedding Model

Edit `src/vector_store.py`:
```python
model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
# Try other models from HuggingFace
```

## ğŸ› ï¸ Troubleshooting

### "No module named 'src'"
Make sure you're running from the `contract_rag` directory.

### "Ollama connection error"
Ensure Ollama is running:
```bash
ollama serve
```

### Slow embedding creation
First-time processing is slow (downloads models). Subsequent runs are fast.

### Database errors
Delete `data/chroma_db/` and re-process PDFs:
```bash
rm -rf data/chroma_db
```

## ğŸ“Š Performance

- **Initial Setup**: 2-5 minutes (model downloads)
- **PDF Processing**: ~30 seconds per PDF
- **Question Answering**: 3-10 seconds per question
- **Database Loading**: 1-2 seconds

## ğŸ” Privacy & Security

- âœ… All data stays on your local machine
- âœ… No external API calls
- âœ… No internet required after setup
- âœ… Your contracts never leave your computer

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- **Ollama** - Local LLM runtime
- **ChromaDB** - Vector database
- **LangChain** - RAG framework
- **Streamlit** - Web interface
- **HuggingFace** - Embedding models

## ğŸ¤ Contributing

Feel free to open issues or submit pull requests!

## ğŸ“§ Support

For questions or issues, please open a GitHub issue.

---

**Built with â¤ï¸ using 100% local, open-source tools**
